{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af810f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing  import OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose        import ColumnTransformer\n",
    "from sklearn.pipeline       import Pipeline\n",
    "from sklearn.impute         import SimpleImputer\n",
    "\n",
    "# Quantile regressors we’ll try in Phase 2\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3dd4362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2️⃣ Path helpers (same as before)\n",
    "NB_DIR   = Path.cwd()\n",
    "ROOT_DIR = NB_DIR.parent\n",
    "DATA_DIR = ROOT_DIR / \"dataset\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cd20c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 47) (200000, 46)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sale_date</th>\n",
       "      <th>sale_price</th>\n",
       "      <th>sale_nbr</th>\n",
       "      <th>sale_warning</th>\n",
       "      <th>join_status</th>\n",
       "      <th>join_year</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>area</th>\n",
       "      <th>...</th>\n",
       "      <th>view_olympics</th>\n",
       "      <th>view_cascades</th>\n",
       "      <th>view_territorial</th>\n",
       "      <th>view_skyline</th>\n",
       "      <th>view_sound</th>\n",
       "      <th>view_lakewash</th>\n",
       "      <th>view_lakesamm</th>\n",
       "      <th>view_otherwater</th>\n",
       "      <th>view_other</th>\n",
       "      <th>submarket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2014-11-15</td>\n",
       "      <td>236000</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td>nochg</td>\n",
       "      <td>2025</td>\n",
       "      <td>47.2917</td>\n",
       "      <td>-122.3658</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1999-01-15</td>\n",
       "      <td>313300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>nochg</td>\n",
       "      <td>2025</td>\n",
       "      <td>47.6531</td>\n",
       "      <td>-122.1996</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2006-08-15</td>\n",
       "      <td>341000</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>nochg</td>\n",
       "      <td>2025</td>\n",
       "      <td>47.4733</td>\n",
       "      <td>-122.1901</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   sale_date  sale_price  sale_nbr sale_warning join_status  join_year  \\\n",
       "0   0  2014-11-15      236000       2.0                    nochg       2025   \n",
       "1   1  1999-01-15      313300       NaN          26        nochg       2025   \n",
       "2   2  2006-08-15      341000       1.0                    nochg       2025   \n",
       "\n",
       "   latitude  longitude  area  ... view_olympics view_cascades  \\\n",
       "0   47.2917  -122.3658    53  ...             0             0   \n",
       "1   47.6531  -122.1996    74  ...             0             0   \n",
       "2   47.4733  -122.1901    30  ...             0             0   \n",
       "\n",
       "  view_territorial  view_skyline  view_sound  view_lakewash  view_lakesamm  \\\n",
       "0                0             0           0              0              0   \n",
       "1                0             0           0              1              0   \n",
       "2                0             0           0              0              0   \n",
       "\n",
       "   view_otherwater  view_other  submarket  \n",
       "0                0           0          I  \n",
       "1                0           0          Q  \n",
       "2                0           0          K  \n",
       "\n",
       "[3 rows x 47 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(DATA_DIR / \"dataset.csv\")   # has sale_price\n",
    "test_df  = pd.read_csv(DATA_DIR / \"test.csv\")\n",
    "TARGET   = \"sale_price\"\n",
    "ID       = \"id\"\n",
    "\n",
    "print(train_df.shape, test_df.shape)\n",
    "train_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8565b5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 49) (200000, 48)\n"
     ]
    }
   ],
   "source": [
    "def load_and_clean():\n",
    "    train = pd.read_csv(DATA_DIR / \"dataset.csv\")\n",
    "    test  = pd.read_csv(DATA_DIR / \"test.csv\")\n",
    "\n",
    "    # ----------  date parsing  ----------\n",
    "    for df in (train, test):\n",
    "        df[\"sale_date\"] = pd.to_datetime(df[\"sale_date\"])\n",
    "        df[\"sale_year\"]     = df[\"sale_date\"].dt.year.astype(\"int16\")\n",
    "        df[\"sale_month\"]    = df[\"sale_date\"].dt.month.astype(\"int8\")\n",
    "        df[\"sale_quarter\"]  = df[\"sale_date\"].dt.quarter.astype(\"int8\")\n",
    "        df.drop(columns=\"sale_date\", inplace=True)\n",
    "\n",
    "        # ----------  numeric coercion ----------\n",
    "        # (sale_nbr / sale_warning look numeric but came in as object)\n",
    "        for col in [\"sale_nbr\", \"sale_warning\"]:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "        # drop super-low-variance columns (e.g., join_year if constant 2025)\n",
    "        nunique_small = [c for c in df.columns if df[c].nunique(dropna=False) <= 1]\n",
    "        df.drop(columns=nunique_small, inplace=True)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "train_df, test_df = load_and_clean()\n",
    "print(train_df.shape, test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0a526d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_preprocessor(df):\n",
    "    num_cols = df.select_dtypes(include=[\"int16\", \"int32\", \"int64\",\n",
    "                                         \"float16\", \"float32\", \"float64\", \"int8\"]).columns\n",
    "    num_cols = num_cols.drop([ID, TARGET], errors=\"ignore\")\n",
    "\n",
    "    cat_cols = df.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns\n",
    "\n",
    "    numeric_pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\",  StandardScaler())\n",
    "    ])\n",
    "\n",
    "    cat_pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        [(\"num\", numeric_pipe, num_cols),\n",
    "         (\"cat\", cat_pipe,   cat_cols)],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "    return preprocessor, num_cols, cat_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a716ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 5\n",
    "cv = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "train_idx, val_idx = next(cv.split(train_df))\n",
    "\n",
    "X_train = train_df.iloc[train_idx].copy()\n",
    "X_val   = train_df.iloc[val_idx].copy()\n",
    "y_train = X_train.pop(TARGET)\n",
    "y_val   = X_val.pop(TARGET)\n",
    "\n",
    "prep, num_cols, cat_cols = build_preprocessor(train_df)\n",
    "\n",
    "X_train_t = prep.fit_transform(X_train)\n",
    "X_val_t   = prep.transform(X_val)\n",
    "X_test_t  = prep.transform(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "163b2709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3546\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 161998.750000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007827 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3546\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 1789000.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage @2.5–97.5 %: 87.790%\n"
     ]
    }
   ],
   "source": [
    "params = dict(\n",
    "    n_estimators=1500,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=256,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    max_depth=-1\n",
    ")\n",
    "\n",
    "lo_m = lgb.LGBMRegressor(objective=\"quantile\", alpha=0.025, **params)\n",
    "hi_m = lgb.LGBMRegressor(objective=\"quantile\", alpha=0.975, **params)\n",
    "\n",
    "lo_m.fit(X_train_t, y_train)\n",
    "hi_m.fit(X_train_t, y_train)\n",
    "\n",
    "lo_pred = lo_m.predict(X_val_t)\n",
    "hi_pred = hi_m.predict(X_val_t)\n",
    "coverage = ((y_val >= lo_pred) & (y_val <= hi_pred)).mean()\n",
    "print(f\"Coverage @2.5–97.5 %: {coverage:.3%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af2ddf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lgb_quantile(X_tr, y_tr, a_lo=0.025, a_hi=0.975, random_state=0):\n",
    "    common = dict(\n",
    "        objective=\"quantile\",\n",
    "        n_estimators=1200,\n",
    "        learning_rate=0.03,\n",
    "        num_leaves=256,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        max_depth=-1,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    lo = lgb.LGBMRegressor(alpha=a_lo, **common)\n",
    "    hi = lgb.LGBMRegressor(alpha=a_hi, **common)\n",
    "    lo.fit(X_tr, y_tr)\n",
    "    hi.fit(X_tr, y_tr)\n",
    "    return lo, hi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a090bda5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

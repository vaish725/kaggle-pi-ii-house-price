{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89901e4f",
   "metadata": {},
   "source": [
    "# Ensemble Quantile Regression with Weight Search\n",
    "*Generated: 2025-06-02 17:51 UTC*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b24ec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "SEEDS = [0,1,2,3,4]\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "NB_DIR = Path.cwd()\n",
    "ROOT_DIR = NB_DIR.parent\n",
    "DATA_DIR = ROOT_DIR / 'dataset'\n",
    "ASSETS = ROOT_DIR / 'assets'\n",
    "ASSETS.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eee41f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 47) (200000, 46)\n"
     ]
    }
   ],
   "source": [
    "ID = 'id'; TARGET = 'sale_price'\n",
    "train_df = pd.read_csv(DATA_DIR/'dataset.csv')\n",
    "test_df  = pd.read_csv(DATA_DIR/'test.csv')\n",
    "print(train_df.shape, test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d7d7d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkvai\\AppData\\Local\\Temp\\ipykernel_38332\\2743806247.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['sale_nbr'].fillna(df['sale_nbr'].median(), inplace=True)\n",
      "C:\\Users\\vkvai\\AppData\\Local\\Temp\\ipykernel_38332\\2743806247.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['sale_nbr'].fillna(df['sale_nbr'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def enrich(df):\n",
    "    df['log_area'] = np.log1p(df['area'])\n",
    "    lat0, lon0 = 47.6097, -122.3331\n",
    "    df['dist_cbd_km'] = np.sqrt((111*(df['latitude']-lat0))**2 +\n",
    "                                (85*(df['longitude']-lon0))**2)\n",
    "    df['sale_warning'] = df['sale_warning'].astype(str).fillna('missing')\n",
    "    df['sale_nbr'] = pd.to_numeric(df['sale_nbr'], errors='coerce')\n",
    "    df['sale_nbr'].fillna(df['sale_nbr'].median(), inplace=True)\n",
    "    return df\n",
    "\n",
    "train_df = enrich(train_df)\n",
    "test_df  = enrich(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd59675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_preprocessor(df):\n",
    "    num_cols = df.select_dtypes(['int64','float64']).columns.drop([ID,TARGET], errors='ignore')\n",
    "    cat_cols = df.select_dtypes(['object','category']).columns\n",
    "    num_scaled = num_cols.drop(['log_area','dist_cbd_km'], errors='ignore')\n",
    "    numeric_pipe = Pipeline([('imp', SimpleImputer(strategy='median')),\n",
    "                             ('sc', StandardScaler())])\n",
    "    cat_pipe = Pipeline([('imp', SimpleImputer(strategy='most_frequent')),\n",
    "                         ('enc', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))])\n",
    "    pre = ColumnTransformer([\n",
    "        ('num', numeric_pipe, num_scaled),\n",
    "        ('cat', cat_pipe, cat_cols),\n",
    "        ('pas', 'passthrough', ['log_area','dist_cbd_km'])\n",
    "    ])\n",
    "    return pre\n",
    "\n",
    "pre = build_preprocessor(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4dcaf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "train_idx, val_idx = next(cv.split(train_df))\n",
    "X_train = train_df.iloc[train_idx].copy()\n",
    "X_val   = train_df.iloc[val_idx].copy()\n",
    "y_train = X_train.pop(TARGET)\n",
    "y_val   = X_val.pop(TARGET)\n",
    "\n",
    "X_train_t = pre.fit_transform(X_train)\n",
    "X_val_t   = pre.transform(X_val)\n",
    "X_test_t  = pre.transform(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbb0ca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lgb_quantile(X, y, a_lo=0.05, a_hi=0.95, random_state=0):\n",
    "    params = dict(\n",
    "        n_estimators=1200, learning_rate=0.03, max_depth=-1,\n",
    "        num_leaves=256, subsample=0.9, colsample_bytree=0.9,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    lo = lgb.LGBMRegressor(objective='quantile', alpha=a_lo, **params)\n",
    "    hi = lgb.LGBMRegressor(objective='quantile', alpha=a_hi, **params)\n",
    "    lo.fit(X, y); hi.fit(X, y)\n",
    "    return lo, hi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff6b3aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4154\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 185000.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4154\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 1435000.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4154\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 185000.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4154\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 1435000.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006733 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4154\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 185000.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4154\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 1435000.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4154\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 185000.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4154\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 1435000.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4154\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 185000.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007606 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4154\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 1435000.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "preds_lo_test, preds_hi_test = [], []\n",
    "preds_lo_val,  preds_hi_val  = [], []\n",
    "\n",
    "for seed in SEEDS:\n",
    "    lo, hi = fit_lgb_quantile(X_train_t, y_train, 0.05, 0.95, seed)\n",
    "    preds_lo_test.append(lo.predict(X_test_t))\n",
    "    preds_hi_test.append(hi.predict(X_test_t))\n",
    "    preds_lo_val.append(lo.predict(X_val_t))\n",
    "    preds_hi_val.append(hi.predict(X_val_t))\n",
    "\n",
    "lgb_lo_test = np.mean(preds_lo_test, axis=0)\n",
    "lgb_hi_test = np.mean(preds_hi_test, axis=0)\n",
    "lgb_lo_val  = np.mean(preds_lo_val,  axis=0)\n",
    "lgb_hi_val  = np.mean(preds_hi_val,  axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4609074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_lo = CatBoostRegressor(loss_function='Quantile:alpha=0.05',\n",
    "                            iterations=1300, depth=8, learning_rate=0.03,\n",
    "                            random_seed=RANDOM_STATE, verbose=False)\n",
    "cat_hi = CatBoostRegressor(loss_function='Quantile:alpha=0.95',\n",
    "                            iterations=1300, depth=8, learning_rate=0.03,\n",
    "                            random_seed=RANDOM_STATE, verbose=False)\n",
    "cat_lo.fit(X_train_t, y_train)\n",
    "cat_hi.fit(X_train_t, y_train)\n",
    "\n",
    "cat_lo_test = cat_lo.predict(X_test_t)\n",
    "cat_hi_test = cat_hi.predict(X_test_t)\n",
    "cat_lo_val  = cat_lo.predict(X_val_t)\n",
    "cat_hi_val  = cat_hi.predict(X_val_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0313c490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best weight: 0.50, Winkler: 337,219\n"
     ]
    }
   ],
   "source": [
    "def winkler(y, lo, hi, alpha=0.10):\n",
    "    y, lo, hi = map(np.asarray, (y, lo, hi))\n",
    "    width = hi - lo\n",
    "    penalty = (2/alpha)*(np.clip(lo - y, 0, None) + np.clip(y - hi, 0, None))\n",
    "    return width + penalty\n",
    "\n",
    "best_w, best_wink, best_q = None, 1e12, None\n",
    "for w in np.linspace(0,1,21):\n",
    "    lo_val = w*lgb_lo_val + (1-w)*cat_lo_val\n",
    "    hi_val = w*lgb_hi_val + (1-w)*cat_hi_val\n",
    "    scores = np.maximum(y_val - hi_val, lo_val - y_val)\n",
    "    q_hat_tmp = np.quantile(scores, 0.90)\n",
    "    wink = winkler(y_val, lo_val - q_hat_tmp, hi_val + q_hat_tmp).mean()\n",
    "    if wink < best_wink:\n",
    "        best_w, best_wink, best_q = w, wink, q_hat_tmp\n",
    "\n",
    "print(f'Best weight: {best_w:.2f}, Winkler: {best_wink:,.0f}')\n",
    "\n",
    "# Apply best weight\n",
    "pi_lower_raw_val = best_w*lgb_lo_val + (1-best_w)*cat_lo_val\n",
    "pi_upper_raw_val = best_w*lgb_hi_val + (1-best_w)*cat_hi_val\n",
    "pi_lower_raw_test = best_w*lgb_lo_test + (1-best_w)*cat_lo_test\n",
    "pi_upper_raw_test = best_w*lgb_hi_test + (1-best_w)*cat_hi_test\n",
    "q_hat = best_q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e77d9648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation coverage: 90.000%, Winkler: 337,219\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.10\n",
    "pi_lower = (pi_lower_raw_test - q_hat).clip(min=0)\n",
    "pi_upper = np.maximum(pi_upper_raw_test + q_hat, pi_lower)\n",
    "\n",
    "coverage_val = ((y_val >= pi_lower_raw_val - q_hat) &\n",
    "                (y_val <= pi_upper_raw_val + q_hat)).mean()\n",
    "val_wink = winkler(y_val, pi_lower_raw_val - q_hat, pi_upper_raw_val + q_hat).mean()\n",
    "print(f'Validation coverage: {coverage_val:.3%}, Winkler: {val_wink:,.0f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb36c0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission: e:\\Hackathons\\Kaggle Prediction interval competition II House price\\assets\\ensemble_weightsearch_cqr_june2.csv\n"
     ]
    }
   ],
   "source": [
    "sub = pd.DataFrame({ID: test_df[ID],\n",
    "                    'pi_lower': pi_lower,\n",
    "                    'pi_upper': pi_upper})\n",
    "csv_path = ASSETS/'ensemble_weightsearch_cqr_june2.csv'\n",
    "sub.to_csv(csv_path, index=False)\n",
    "print('Saved submission:', csv_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

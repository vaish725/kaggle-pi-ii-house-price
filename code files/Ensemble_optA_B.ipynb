{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c55b8f2",
   "metadata": {},
   "source": [
    "# Ensemble Quantile Regression — CatBoost‑Raw + Adaptive Conformal\n",
    "*Generated 2025-06-02 18:00 UTC* \n",
    "\n",
    "This notebook:\n",
    "1. Builds feature‑engineered LightGBM bag (5 seeds, preprocessed).\n",
    "2. Trains CatBoost quantile **directly on raw categoricals**.\n",
    "3. Finds the best weight blend via Winkler grid search.\n",
    "4. Applies **bin‑wise adaptive conformal padding** to hit 90 % coverage while minimising width.\n",
    "5. Writes `assets/ensemble_catraw_adaptpad.csv` ready for Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c652fb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "SEEDS = [0,1,2,3,4]\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "NB_DIR = Path.cwd()\n",
    "ROOT_DIR = NB_DIR.parent\n",
    "DATA_DIR = ROOT_DIR / 'dataset'\n",
    "ASSETS   = ROOT_DIR / 'assets'\n",
    "ASSETS.mkdir(exist_ok=True, parents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "247befee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 47) (200000, 46)\n"
     ]
    }
   ],
   "source": [
    "ID='id'; TARGET='sale_price'\n",
    "train_df = pd.read_csv(DATA_DIR/'dataset.csv')\n",
    "test_df  = pd.read_csv(DATA_DIR/'test.csv')\n",
    "print(train_df.shape, test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fc975a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkvai\\AppData\\Local\\Temp\\ipykernel_35560\\1396941212.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['sale_nbr'].fillna(df['sale_nbr'].median(), inplace=True)\n",
      "C:\\Users\\vkvai\\AppData\\Local\\Temp\\ipykernel_35560\\1396941212.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['sale_nbr'].fillna(df['sale_nbr'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def enrich(df):\n",
    "    df['log_area'] = np.log1p(df['area'])\n",
    "    lat0, lon0 = 47.6097, -122.3331\n",
    "    df['dist_cbd_km'] = np.sqrt((111*(df['latitude']-lat0))**2 +\n",
    "                                (85*(df['longitude']-lon0))**2)\n",
    "    df['sale_warning'] = df['sale_warning'].astype(str).fillna('missing')\n",
    "    df['sale_nbr'] = pd.to_numeric(df['sale_nbr'], errors='coerce')\n",
    "    df['sale_nbr'].fillna(df['sale_nbr'].median(), inplace=True)\n",
    "    return df\n",
    "\n",
    "train_df = enrich(train_df); test_df = enrich(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eda0bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pre(df):\n",
    "    num_cols = df.select_dtypes(['int64','float64']).columns.drop([ID, TARGET], errors='ignore')\n",
    "    cat_cols = df.select_dtypes(['object','category']).columns\n",
    "    num_scaled = num_cols.drop(['log_area','dist_cbd_km'], errors='ignore')\n",
    "    num_pipe = Pipeline([('imp', SimpleImputer(strategy='median')),\n",
    "                         ('sc', StandardScaler())])\n",
    "    cat_pipe = Pipeline([('imp', SimpleImputer(strategy='most_frequent')),\n",
    "                         ('enc', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))])\n",
    "    return ColumnTransformer([\n",
    "        ('num', num_pipe, num_scaled),\n",
    "        ('cat', cat_pipe, cat_cols),\n",
    "        ('pas', 'passthrough', ['log_area','dist_cbd_km'])\n",
    "    ])\n",
    "\n",
    "pre = build_pre(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6148ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "train_idx, val_idx = next(cv.split(train_df))\n",
    "X_train = train_df.iloc[train_idx].copy()\n",
    "X_val   = train_df.iloc[val_idx].copy()\n",
    "y_train = X_train.pop(TARGET)\n",
    "y_val   = X_val.pop(TARGET)\n",
    "\n",
    "X_train_t = pre.fit_transform(X_train)\n",
    "X_val_t   = pre.transform(X_val)\n",
    "X_test_t  = pre.transform(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea12702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4154\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 185000.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4154\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 1435000.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4154\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 185000.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4154\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 1435000.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4154\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 185000.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4154\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 1435000.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4154\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 185000.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4154\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 1435000.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4154\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 185000.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4154\n",
      "[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 1435000.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vkvai\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def fit_lgbq(X, y, a_lo=0.05, a_hi=0.95, seed=0):\n",
    "    params = dict(n_estimators=1200, learning_rate=0.03, max_depth=-1,\n",
    "                  num_leaves=256, subsample=0.9, colsample_bytree=0.9,\n",
    "                  random_state=seed)\n",
    "    lo = lgb.LGBMRegressor(objective='quantile', alpha=a_lo, **params)\n",
    "    hi = lgb.LGBMRegressor(objective='quantile', alpha=a_hi, **params)\n",
    "    lo.fit(X, y); hi.fit(X, y)\n",
    "    return lo, hi\n",
    "\n",
    "preds_lo_test, preds_hi_test = [], []\n",
    "preds_lo_val, preds_hi_val = [], []\n",
    "\n",
    "for s in SEEDS:\n",
    "    lo, hi = fit_lgbq(X_train_t, y_train, 0.05, 0.95, s)\n",
    "    preds_lo_test.append(lo.predict(X_test_t))\n",
    "    preds_hi_test.append(hi.predict(X_test_t))\n",
    "    preds_lo_val.append(lo.predict(X_val_t))\n",
    "    preds_hi_val.append(hi.predict(X_val_t))\n",
    "\n",
    "lgb_lo_test = np.mean(preds_lo_test, axis=0)\n",
    "lgb_hi_test = np.mean(preds_hi_test, axis=0)\n",
    "lgb_lo_val  = np.mean(preds_lo_val, axis=0)\n",
    "lgb_hi_val  = np.mean(preds_hi_val, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d3d8898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---  CLEAN  ALL  CATEGORICAL  NaNs  ---------------------------\n",
    "for df in (train_df, X_val, test_df):\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].astype(str).fillna(\"missing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a6fd614",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = train_df.select_dtypes('object').columns.tolist()\n",
    "num_cols = [c for c in train_df.columns if c not in cat_cols + [ID, TARGET]]\n",
    "\n",
    "cat_lo = CatBoostRegressor(loss_function='Quantile:alpha=0.05',\n",
    "                           iterations=1600, depth=8, learning_rate=0.03,\n",
    "                           random_seed=RANDOM_STATE, verbose=False,\n",
    "                           cat_features=cat_cols)\n",
    "cat_hi = CatBoostRegressor(loss_function='Quantile:alpha=0.95',\n",
    "                           iterations=1600, depth=8, learning_rate=0.03,\n",
    "                           random_seed=RANDOM_STATE, verbose=False,\n",
    "                           cat_features=cat_cols)\n",
    "\n",
    "cat_lo.fit(train_df[cat_cols+num_cols], train_df[TARGET])\n",
    "cat_hi.fit(train_df[cat_cols+num_cols], train_df[TARGET])\n",
    "\n",
    "cat_lo_val  = cat_lo.predict(X_val[cat_cols+num_cols])\n",
    "cat_hi_val  = cat_hi.predict(X_val[cat_cols+num_cols])\n",
    "cat_lo_test = cat_lo.predict(test_df[cat_cols+num_cols])\n",
    "cat_hi_test = cat_hi.predict(test_df[cat_cols+num_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec45b005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best weight: 0.20, Winkler: 316,879, q̂: 1,668\n"
     ]
    }
   ],
   "source": [
    "def winkler(y, lo, hi, alpha=0.10):\n",
    "    y, lo, hi = map(np.asarray, (y, lo, hi))\n",
    "    width = hi - lo\n",
    "    penalty = (2/alpha)*(np.clip(lo - y, 0, None)+np.clip(y - hi, 0, None))\n",
    "    return width + penalty\n",
    "\n",
    "best_w, best_wink, best_lo_val, best_hi_val, best_q = None, 1e12, None, None, None\n",
    "for w in np.linspace(0,1,21):\n",
    "    lo_val = w*lgb_lo_val + (1-w)*cat_lo_val\n",
    "    hi_val = w*lgb_hi_val + (1-w)*cat_hi_val\n",
    "    scores = np.maximum(y_val - hi_val, lo_val - y_val)\n",
    "    q_tmp = np.quantile(scores, 0.90)\n",
    "    wink = winkler(y_val, lo_val - q_tmp, hi_val + q_tmp).mean()\n",
    "    if wink < best_wink:\n",
    "        best_w, best_wink, best_lo_val, best_hi_val, best_q = w, wink, lo_val, hi_val, q_tmp\n",
    "\n",
    "print(f'Best weight: {best_w:.2f}, Winkler: {best_wink:,.0f}, q̂: {best_q:,.0f}')\n",
    "\n",
    "# Build raw test with best weight\n",
    "pi_lower_raw_val = best_w*lgb_lo_val + (1-best_w)*cat_lo_val\n",
    "pi_upper_raw_val = best_w*lgb_hi_val + (1-best_w)*cat_hi_val\n",
    "pi_lower_raw_test = best_w*lgb_lo_test + (1-best_w)*cat_lo_test\n",
    "pi_upper_raw_test = best_w*lgb_hi_test + (1-best_w)*cat_hi_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d400ce95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive coverage: 90.000%, Winkler: 316,184\n"
     ]
    }
   ],
   "source": [
    "# determine bins on validation widths\n",
    "raw_width_val = pi_upper_raw_val - pi_lower_raw_val\n",
    "n_bins = 10\n",
    "val_bins = pd.qcut(raw_width_val, q=n_bins, labels=False, duplicates='drop')\n",
    "bin_q = np.zeros(n_bins)\n",
    "\n",
    "for b in range(n_bins):\n",
    "    mask = val_bins == b\n",
    "    s = np.maximum(y_val.values[mask] - pi_upper_raw_val[mask],\n",
    "                   pi_lower_raw_val[mask] - y_val.values[mask])\n",
    "    bin_q[b] = np.quantile(s, 0.90)\n",
    "\n",
    "# Map test widths into same bins\n",
    "bin_edges = np.quantile(raw_width_val, np.linspace(0,1,n_bins+1))\n",
    "test_bins = np.clip(np.digitize(pi_upper_raw_test - pi_lower_raw_test, bin_edges, right=False)-1, 0, n_bins-1)\n",
    "pad = bin_q[test_bins]\n",
    "\n",
    "pi_lower = (pi_lower_raw_test - pad).clip(min=0)\n",
    "pi_upper = np.maximum(pi_upper_raw_test + pad, pi_lower)\n",
    "\n",
    "# Validation sanity\n",
    "pad_val = bin_q[val_bins]\n",
    "cov_val = ((y_val >= pi_lower_raw_val - pad_val) & (y_val <= pi_upper_raw_val + pad_val)).mean()\n",
    "wink_val = winkler(y_val, pi_lower_raw_val - pad_val, pi_upper_raw_val + pad_val).mean()\n",
    "print(f'Adaptive coverage: {cov_val:.3%}, Winkler: {wink_val:,.0f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2230edde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: e:\\Hackathons\\Kaggle Prediction interval competition II House price\\assets\\ensemble_catraw_adaptpad_june2.csv\n"
     ]
    }
   ],
   "source": [
    "sub = pd.DataFrame({ID: test_df[ID], 'pi_lower': pi_lower, 'pi_upper': pi_upper})\n",
    "csv_path = ASSETS/'ensemble_catraw_adaptpad_june2.csv'\n",
    "sub.to_csv(csv_path, index=False)\n",
    "print('Saved:', csv_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
